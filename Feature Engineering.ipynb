{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1257d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01 What is a parameter?\n",
    "\"\"\"\n",
    "In ML, a parameter is a value that the model learns from the training data.\n",
    "These values define how the model makes predictions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3527c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02 What is correlation?\n",
    "# What does negative correlation mean?\n",
    "\"\"\"\n",
    "Correlation is a statistical measure that describes the strength and direction of the relationship between two variables.\n",
    "It’s usually represented by the correlation coefficient (r), which ranges from -1 to +1:\n",
    "A negative correlation means that as one variable increases, the other decreases.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b26df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03 Define Machine Learning. What are the main components in Machine Learning?\n",
    "\"\"\"\n",
    "Machine Learning is a branch of Artificial Intelligence (AI) that focuses on\n",
    "building systems that can learn patterns from data and make decisions or\n",
    "predictions.\n",
    "\n",
    "main components of Machine Learning:\n",
    "Data\n",
    "FeaturesModel\n",
    "Parameters\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04 How does loss value help in determining whether the model is good or not?\n",
    "\"\"\"\n",
    "The loss value (also called cost or error) is a number that tells us how far the model’s predictions are from the actual values.\n",
    "How it helps determine model quality:\n",
    "Low Loss Value → Predictions are close to actual values → Model is performing wel\n",
    "High Loss Value → Predictions are far from actual values → Model is performing poorly.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cab3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05 What are continuous and categorical variables?\n",
    "\"\"\"\n",
    "Continuous Variables\n",
    "Variables that can take any numerical value within a range.\n",
    "They are measurable and often come from real-world measurements.\n",
    "\n",
    "Categorical Variables\n",
    "Variables that represent categories, labels, or groups.\n",
    "They are not numerical by nature, though sometimes encoded as numbers.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81456fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06 How do we handle categorical variables in Machine Learning? What are the common\n",
    "# techniques?\n",
    "\"\"\"\n",
    "Categorical variables must be converted into numerical form since ML models work with numbers.\n",
    "\n",
    "Common Techniques:\n",
    "Label Encoding : Assigns unique integers to each category.\n",
    "One-Hot Encoding : Creates binary columns for each category.\n",
    "Ordinal Encoding : Maps categories to integers when there’s a natural order.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f166e971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 07 What do you mean by training and testing a dataset?\n",
    "\"\"\"\n",
    "The training set is the portion of the dataset used to \"teach\" the machine learning model.\n",
    "Testing is the process of evaluating the model using unseen data called the test dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5153a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 08 What is sklearn.preprocessing?\n",
    "\"\"\"\n",
    "It is a module in scikit-learn (a popular Python ML library) used for preprocessing or transforming data before feeding it into a machine learning model.\n",
    "Preprocessing helps improve model performance, training speed, and accuracy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c71c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 09 What is a Test set?\n",
    "\"\"\"\n",
    "The test set is a subset of the dataset that is kept separate from the training data.\n",
    "It is used to evaluate how well a trained machine learning model performs on new, unseen data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ba8999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 How do we split data for model fitting (training and testing) in Python?\n",
    "# How do you approach a Machine Learning problem?\n",
    "\n",
    "\"\"\"\n",
    "Use train_test_split from scikit-learn to divide data into training and test sets, e.g., X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42).\n",
    "\n",
    "Approach to a Machine Learning Problem:\n",
    "Define the problem and collect data.\n",
    "Preprocess data (handle missing values, encode categories, scale features).\n",
    "Split data, train a model, and evaluate using metrics on the test set.\n",
    "Tune hyperparameters if needed and use the model for predictions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd2cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 Why do we have to perform EDA before fitting a model to the data?\n",
    "\"\"\"\n",
    "Understand the Data : Know the distribution, types of variables, and relationships between features.\n",
    "Detect Missing Values & Outliers : Clean the data to prevent biased or inaccurate models.\n",
    "Identify Feature Importance : Helps select the most relevant features for better performance.\n",
    "Spot Patterns & Trends : Reveals insights that guide feature engineering and model choice.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ff2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 What is correlation?\n",
    "\"\"\"\n",
    "Correlation is a statistical measure that describes the strength and direction of the relationship between two variables.\n",
    "It’s usually represented by the correlation coefficient (r), which ranges from -1 to +1:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cd49f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 What does negative correlation mean?\n",
    "\"\"\"\n",
    "A negative correlation means that as one variable increases, the other decreases.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19174d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aditi\\anaconda3\\py\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\aditi\\anaconda3\\py\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\aditi\\anaconda3\\py\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     X    Y    Z\n",
      "X  1.0  1.0 -0.9\n",
      "Y  1.0  1.0 -0.9\n",
      "Z -0.9 -0.9  1.0\n"
     ]
    }
   ],
   "source": [
    "# 14 How can you find correlation between variables in Python?\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'X': [1, 2, 3, 4, 5],\n",
    "    'Y': [2, 4, 6, 8, 10],\n",
    "    'Z': [5, 3, 4, 2, 1]\n",
    "})\n",
    "corr_matrix = df.corr()\n",
    "print(corr_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fe2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 what is causation? Explain difference between correlation and causation with an example.\n",
    "\"\"\"\n",
    "Causation means that one variable directly causes a change in another variable.\n",
    "\n",
    "Difference:\n",
    "\n",
    "Correlation: No cause-effect is implied.\n",
    "Causation: There is a direct cause-effect relationship.\n",
    "\n",
    "Correlation: No cause-effect is implied.\n",
    "Causation: There is a direct cause-effect relationship.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cb81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. What is an Optimizer? What are different types of optimizers? Explain each with an example\n",
    "\"\"\"\n",
    "In Machine Learning, an optimizer is an algorithm used to update the model’s parameters (weights and biases) during training to minimize the loss function\n",
    "\n",
    "Common Types of Optimizers\n",
    "1. Gradient Descent (GD)\n",
    "Updates parameters using the average gradient of the loss function over the entire training dataset.\n",
    "Example: Linear regression on small datasets.\n",
    "2. Stochastic Gradient Descent (SGD)\n",
    "Updates parameters for each training example, rather than the whole dataset.\n",
    "\n",
    "3. Mini-Batch Gradient Descent\n",
    "Updates parameters using small batches of data (between GD and SGD).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. What is sklearn.linear_model ?\n",
    "\"\"\"\n",
    "It is a module in scikit-learn that provides linear models for regression and classification tasks.\n",
    "Linear models try to fit a linear relationship between input features (X) and output (y).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d670b246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. What does model.fit() do? What arguments must be given?\n",
    "\"\"\"\n",
    "Trains the machine learning model using the training data.\n",
    "Args:\n",
    "Arguments:\n",
    "\n",
    "X → Input features.\n",
    "y → Target/output variable.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be2785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19. What does model.predict() do? What arguments must be given?\n",
    "\"\"\"\n",
    "Uses the trained model to make predictions on new data.\n",
    "\n",
    "Args:\n",
    "X → New input features\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce4e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20. What are continuous and categorical variables?\n",
    "\"\"\"\n",
    "Continuous Variables : Variables that can take any numerical value within a range.\n",
    "Examples: Height (170.5 cm, 171.2 cm)\n",
    "\n",
    "Categorical Variables : Variables that represent categories, labels, or groups.\n",
    "Examples : Gender (Male, Female, Other)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21. What is feature scaling? How does it help in Machine Learning?\n",
    "\"\"\"\n",
    "Feature scaling is the process of normalizing or standardizing the range of independent variables (features) in a dataset.\n",
    "\n",
    "Why Feature Scaling Helps in Machine Learning:\n",
    "Reduces Training time.\n",
    "Stabalize Training\n",
    "Improves Accuracy for distance based models\n",
    "prevents feature dominance\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d17a1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    ]\n",
      " [0.125 ]\n",
      " [0.375 ]\n",
      " [0.6875]\n",
      " [1.    ]]\n"
     ]
    }
   ],
   "source": [
    "# 22. How do we perform scaling in Python?\n",
    "\"\"\"\n",
    "Min-Max Scaling (0–1 range)\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Age': [18, 22, 30, 40, 50]})\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df)  \n",
    "print(df_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc66ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.19349009]\n",
      " [-0.85249292]\n",
      " [-0.17049858]\n",
      " [ 0.68199434]\n",
      " [ 1.53448726]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Standardization\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_standardized = scaler.fit_transform(df)\n",
    "print(df_standardized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d841f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23. What is sklearn.preprocessing?\n",
    "\"\"\"\n",
    "It is a module in scikit-learn that provides tools to preprocess and transform data before feeding it into machine learning models.\n",
    "Preprocessing helps improve model performance, training speed, and accuracy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9d8602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (120, 4)\n",
      "X_test shape: (30, 4)\n",
      "y_train shape: (120,)\n",
      "y_test shape: (30,)\n"
     ]
    }
   ],
   "source": [
    "# 24. How do we split data for model fitting (training and testing) in Python?\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = pd.Series(iris.target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d3670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25. Explain data encoding?\n",
    "\"\"\"\n",
    "Data encoding is the process of converting categorical data into numerical form so that machine learning models can work with it.\n",
    "Machine learning models cannot understand text labels directly.\n",
    "Encoding ensures that the information in categorical variables is represented numerically.\n",
    "Helps models detect patterns, relationships, and correlations between features.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
