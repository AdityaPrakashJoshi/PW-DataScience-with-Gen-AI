{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b921f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.  What is Logistic Regression, and how does it differ from Linear\n",
    "# Regression?\n",
    "\"\"\"\n",
    "Logistic Regression is a classification algorithm used to predict categorical outcomes (like 0 or 1).\n",
    "It uses the sigmoid function to output probabilities between 0 and 1.\n",
    "Linear Regression, on the other hand, predicts continuous numerical values.\n",
    "While Linear Regression fits a straight line, Logistic Regression fits an S-shaped curve.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Explain the role of the Sigmoid function in Logistic Regression.\n",
    "\n",
    "\"\"\"\n",
    "The Sigmoid function in Logistic Regression converts linear output into a probability between 0 and 1.\n",
    "It ensures the predicted values stay within a valid probability range.\n",
    "The functionâ€™s S-shape helps classify outcomes as 0 or 1 using a threshold (usually 0.5).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. What is Regularization in Logistic Regression and why is it needed?\n",
    "\"\"\"\n",
    "Regularization in Logistic Regression is a technique used to prevent overfitting by adding a penalty to large coefficient values.\n",
    "It helps the model generalize better on unseen data.\n",
    "Common types are L1 (Lasso) and L2 (Ridge) regularization.\n",
    "It ensures the model remains simple and avoids capturing noise from the training data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3881461d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. What are some common evaluation metrics for classification models, and\n",
    "# why are they important?\n",
    "\"\"\"\n",
    "Common evaluation metrics for classification models include Accuracy, Precision, Recall, and F1-Score.\n",
    "Accuracy measures overall correctness, while Precision checks how many predicted positives are correct.\n",
    "Recall measures how many actual positives are identified, and F1-Score balances precision and recall.\n",
    "These metrics are important to assess model performance, especially on imbalanced datasets.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42859018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aditi\\anaconda3\\py\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\aditi\\anaconda3\\py\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\aditi\\anaconda3\\py\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.956140350877193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aditi\\anaconda3\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 5. Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
    "# splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
    "# (Use Dataset from sklearn package)\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de78728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[ 1.61099394  0.17716867 -0.16598305  0.00578313 -0.23743461 -0.2195747\n",
      "  -0.71460128 -0.53545326 -0.28883161 -0.00484545 -0.14466131  1.16927593\n",
      "  -0.27747038 -0.06789438 -0.04125235  0.23852411  0.14862063 -0.0498328\n",
      "  -0.02168155  0.04074207  0.25107059 -0.41307389 -0.0406849  -0.0164506\n",
      "  -0.46602227 -0.41379559 -1.43135273 -0.85419241 -1.02872668 -0.02551256]]\n",
      "Accuracy: 0.956140350877193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aditi\\anaconda3\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 6. Write a Python program to train a Logistic Regression model using L2\n",
    "# regularization (Ridge) and print the model coefficients and accuracy.\n",
    "# (Use Dataset from sklearn package)\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daeec744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Write a Python program to train a Logistic Regression model for multiclass\n",
    "# classification using multi_class='ovr' and print the classification report.\n",
    "# (Use Dataset from sklearn package)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(multi_class='ovr', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d002f2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Validation Accuracy: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "# 8. Write a Python program to apply GridSearchCV to tune C and penalty\n",
    "# hyperparameters for Logistic Regression and print the best parameters and validation\n",
    "# accuracy.\n",
    "# (Use Dataset from sklearn package)\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
    "grid = GridSearchCV(LogisticRegression(solver='liblinear', max_iter=1000), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f9a66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without scaling: 0.956140350877193\n",
      "Accuracy with scaling: 0.9736842105263158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aditi\\anaconda3\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 9. Write a Python program to standardize the features before training Logistic\n",
    "# Regression and compare the model's accuracy with and without scaling.\n",
    "# (Use Dataset from sklearn package)\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model1 = LogisticRegression(max_iter=1000)\n",
    "model1.fit(X_train, y_train)\n",
    "y_pred1 = model1.predict(X_test)\n",
    "acc1 = accuracy_score(y_test, y_pred1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model2 = LogisticRegression(max_iter=1000)\n",
    "model2.fit(X_train_scaled, y_train)\n",
    "y_pred2 = model2.predict(X_test_scaled)\n",
    "acc2 = accuracy_score(y_test, y_pred2)\n",
    "\n",
    "print(\"Accuracy without scaling:\", acc1)\n",
    "print(\"Accuracy with scaling:\", acc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df713d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Imagine you are working at an e-commerce company that wants to\n",
    "# predict which customers will respond to a marketing campaign. Given an imbalanced\n",
    "# dataset (only 5% of customers respond), describe the approach youâ€™d take to build a\n",
    "# Logistic Regression model â€” including data handling, feature scaling, balancing\n",
    "# classes, hyperparameter tuning, and evaluating the model for this real-world business\n",
    "# use case.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Data Handling:\n",
    "    Clean the dataset by handling missing values, encoding categorical variables, and removing irrelevant features. Separate the target (response) from the input features.\n",
    "Feature Scaling:\n",
    "    Standardize numerical features using StandardScaler to ensure that the model weights are balanced and optimization converges faster.\n",
    "Handling Imbalanced Classes:\n",
    "    Since only 5% of customers respond, use techniques like SMOTE (Synthetic Minority Oversampling Technique), Random Oversampling, or class weights in Logistic Regression (class_weight='balanced') to address imbalance.\n",
    "Hyperparameter Tuning:\n",
    "    Use GridSearchCV to tune hyperparameters such as C (regularization strength) and penalty (L1 or L2). Consider cross-validation to ensure robustness.\n",
    "Model Training:\n",
    "    Train the Logistic Regression model with scaled features and balanced classes, ensuring regularization to avoid overfitting.\n",
    "Evaluation Metrics:\n",
    "    Since the dataset is imbalanced, rely on Precision, Recall, F1-Score, and ROC-AUC rather than just accuracy. High recall ensures most responders are captured, and F1-Score balances precision and recall.\n",
    "Business Considerations:\n",
    "    Adjust the probability threshold for predictions to optimize for marketing ROI, e.g., targeting only the top predicted responders rather than all predicted positives.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
